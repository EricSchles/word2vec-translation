{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Install `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (from -r requirements.txt (line 116))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 66kB/s s eta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): en-core-web-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 116))\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.0.0/es_core_news_sm-2.0.0.tar.gz (from -r requirements.txt (line 117))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.0.0/es_core_news_sm-2.0.0.tar.gz (36.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 36.7MB 68kB/s s eta 0:00:01   26% |████████▌                       | 9.7MB 50.6MB/s eta 0:00:01\n",
      "\u001b[?25h  Requirement already satisfied (use --upgrade to upgrade): es-core-news-sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.0.0/es_core_news_sm-2.0.0.tar.gz in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 117))\n",
      "Requirement already satisfied: absl-py==0.1.13 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Requirement already satisfied: astor==0.6.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 2))\n",
      "Requirement already satisfied: autopep8==1.3.5 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 3))\n",
      "Requirement already satisfied: backcall==0.1.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 4))\n",
      "Requirement already satisfied: bleach==1.5.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 5))\n",
      "Requirement already satisfied: boto==2.48.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 6))\n",
      "Requirement already satisfied: boto3==1.7.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 7))\n",
      "Requirement already satisfied: botocore==1.10.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 8))\n",
      "Requirement already satisfied: bz2file==0.98 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 9))\n",
      "Requirement already satisfied: cachetools==2.0.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 10))\n",
      "Requirement already satisfied: certifi==2018.4.16 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 11))\n",
      "Requirement already satisfied: chardet==3.0.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 12))\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 13))\n",
      "Requirement already satisfied: cymem==1.31.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 14))\n",
      "Requirement already satisfied: Cython==0.28.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 15))\n",
      "Requirement already satisfied: cytoolz==0.8.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 16))\n",
      "Requirement already satisfied: decorator==4.3.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 17))\n",
      "Requirement already satisfied: dill==0.2.7.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 18))\n",
      "Requirement already satisfied: docutils==0.14 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 19))\n",
      "Requirement already satisfied: entrypoints==0.2.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 20))\n",
      "Requirement already satisfied: fasttext==0.8.22 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 21))\n",
      "Requirement already satisfied: gast==0.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 22))\n",
      "Requirement already satisfied: gensim==3.4.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 23))\n",
      "Requirement already satisfied: google-api-core==1.1.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 24))\n",
      "Requirement already satisfied: google-auth==1.4.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 25))\n",
      "Requirement already satisfied: google-cloud-core==0.28.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 26))\n",
      "Requirement already satisfied: google-cloud-translate==1.3.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 27))\n",
      "Requirement already satisfied: googleapis-common-protos==1.5.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 28))\n",
      "Requirement already satisfied: grpcio==1.11.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 29))\n",
      "Requirement already satisfied: h5py==2.7.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 30))\n",
      "Requirement already satisfied: html5lib==0.9999999 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 31))\n",
      "Requirement already satisfied: idna==2.6 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 32))\n",
      "Requirement already satisfied: ipykernel==4.8.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 33))\n",
      "Requirement already satisfied: ipython==6.3.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 34))\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 35))\n",
      "Requirement already satisfied: ipywidgets==7.2.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 36))\n",
      "Requirement already satisfied: jedi==0.12.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 37))\n",
      "Requirement already satisfied: Jinja2==2.10 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 38))\n",
      "Requirement already satisfied: jmespath==0.9.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 39))\n",
      "Requirement already satisfied: jsonschema==2.6.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 40))\n",
      "Requirement already satisfied: jupyter==1.0.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 41))\n",
      "Requirement already satisfied: jupyter-client==5.2.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 42))\n",
      "Requirement already satisfied: jupyter-console==5.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 43))\n",
      "Requirement already satisfied: jupyter-contrib-core==0.3.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 44))\n",
      "Requirement already satisfied: jupyter-contrib-nbextensions==0.5.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 45))\n",
      "Requirement already satisfied: jupyter-core==4.4.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 46))\n",
      "Requirement already satisfied: jupyter-highlight-selected-word==0.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 47))\n",
      "Requirement already satisfied: jupyter-latex-envs==1.4.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 48))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter-nbextensions-configurator==0.4.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 49))\n",
      "Requirement already satisfied: Keras==2.1.5 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 50))\n",
      "Requirement already satisfied: kiwisolver==1.0.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 51))\n",
      "Requirement already satisfied: lxml==4.2.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 52))\n",
      "Requirement already satisfied: Markdown==2.6.11 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 53))\n",
      "Requirement already satisfied: MarkupSafe==1.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 54))\n",
      "Requirement already satisfied: matplotlib==2.2.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 55))\n",
      "Requirement already satisfied: mistune==0.8.3 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 56))\n",
      "Requirement already satisfied: msgpack-numpy==0.4.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 57))\n",
      "Requirement already satisfied: msgpack-python==0.5.6 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 58))\n",
      "Requirement already satisfied: murmurhash==0.28.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 59))\n",
      "Requirement already satisfied: nbconvert==5.3.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 60))\n",
      "Requirement already satisfied: nbformat==4.4.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 61))\n",
      "Requirement already satisfied: notebook==5.4.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 62))\n",
      "Requirement already satisfied: numexpr==2.6.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 63))\n",
      "Requirement already satisfied: numpy==1.14.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 64))\n",
      "Requirement already satisfied: pandas==0.22.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 65))\n",
      "Requirement already satisfied: pandocfilters==1.4.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 66))\n",
      "Requirement already satisfied: parso==0.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 67))\n",
      "Requirement already satisfied: pathlib==1.0.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 68))\n",
      "Requirement already satisfied: pexpect==4.5.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 69))\n",
      "Requirement already satisfied: pickleshare==0.7.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 70))\n",
      "Requirement already satisfied: plac==0.9.6 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 71))\n",
      "Requirement already satisfied: preshed==1.0.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 72))\n",
      "Requirement already satisfied: prompt-toolkit==1.0.15 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 73))\n",
      "Requirement already satisfied: protobuf==3.5.2.post1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 74))\n",
      "Requirement already satisfied: ptyprocess==0.5.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 75))\n",
      "Requirement already satisfied: pyasn1==0.4.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 76))\n",
      "Requirement already satisfied: pyasn1-modules==0.2.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 77))\n",
      "Requirement already satisfied: pybind11==2.2.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 78))\n",
      "Requirement already satisfied: pycodestyle==2.4.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 79))\n",
      "Requirement already satisfied: Pygments==2.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 80))\n",
      "Requirement already satisfied: pyparsing==2.2.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 81))\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 82))\n",
      "Requirement already satisfied: pytz==2018.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 83))\n",
      "Requirement already satisfied: PyYAML==3.12 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 84))\n",
      "Requirement already satisfied: pyzmq==17.0.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 85))\n",
      "Requirement already satisfied: qtconsole==4.3.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 86))\n",
      "Requirement already satisfied: regex==2017.4.5 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 87))\n",
      "Requirement already satisfied: requests==2.18.4 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 88))\n",
      "Requirement already satisfied: rsa==3.4.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 89))\n",
      "Requirement already satisfied: s3transfer==0.1.13 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 90))\n",
      "Requirement already satisfied: scikit-learn==0.19.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 91))\n",
      "Requirement already satisfied: scipy==1.0.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 92))\n",
      "Requirement already satisfied: seaborn==0.8.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 93))\n",
      "Requirement already satisfied: Send2Trash==1.5.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 94))\n",
      "Requirement already satisfied: simplegeneric==0.8.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 95))\n",
      "Requirement already satisfied: six==1.11.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 96))\n",
      "Requirement already satisfied: smart-open==1.5.7 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 97))\n",
      "Requirement already satisfied: spacy==2.0.11 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 98))\n",
      "Requirement already satisfied: tables==3.4.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 99))\n",
      "Requirement already satisfied: tensorboard==1.7.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 100))\n",
      "Requirement already satisfied: tensorflow==1.7.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 101))\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 102))\n",
      "Requirement already satisfied: terminado==0.8.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 103))\n",
      "Requirement already satisfied: testpath==0.3.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 104))\n",
      "Requirement already satisfied: thinc==6.10.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 105))\n",
      "Requirement already satisfied: toolz==0.9.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 106))\n",
      "Requirement already satisfied: tornado==5.0.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 107))\n",
      "Requirement already satisfied: tqdm==4.23.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 108))\n",
      "Requirement already satisfied: traitlets==4.3.2 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 109))\n",
      "Requirement already satisfied: ujson==1.35 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 110))\n",
      "Requirement already satisfied: urllib3==1.22 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 111))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wcwidth==0.1.7 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 112))\n",
      "Requirement already satisfied: Werkzeug==0.14.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 113))\n",
      "Requirement already satisfied: widgetsnbextension==3.2.1 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 114))\n",
      "Requirement already satisfied: wrapt==1.10.11 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from -r requirements.txt (line 115))\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from fasttext==0.8.22->-r requirements.txt (line 21))\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages (from tensorboard==1.7.0->-r requirements.txt (line 100))\n",
      "Building wheels for collected packages: en-core-web-sm, es-core-news-sm\n",
      "  Running setup.py bdist_wheel for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stefan/.cache/pip/wheels/54/7c/d8/f86364af8fbba7258e14adae115f18dd2c91552406edc3fdaa\n",
      "  Running setup.py bdist_wheel for es-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/stefan/.cache/pip/wheels/9e/28/c4/df4980946eb229379ed26d349566e427fa029dbf03546ccb94\n",
      "Successfully built en-core-web-sm es-core-news-sm\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[93m    Installed models (spaCy v2.0.11)\u001b[0m\r\n",
      "    /home/stefan/.virtualenvs/word2vec_translate/lib/python3.6/site-packages/spacy\r\n",
      "\r\n",
      "    TYPE        NAME                  MODEL                 VERSION                                   \r\n",
      "    package     es-core-news-sm       es_core_news_sm       \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n",
      "    package     en-core-web-sm        en_core_web_sm        \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n",
      "    link        en_core_web_sm        en_core_web_sm        \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n",
      "    link        en                    en_core_web_sm        \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n",
      "    link        es                    es_core_news_sm       \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n",
      "    link        es_core_news_sm       es_core_news_sm       \u001b[38;5;2m2.0.0\u001b[0m    \u001b[38;5;2m✔\u001b[0m      \r\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os, tarfile, sys\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "import spacy\n",
    "\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('float_format', '{:,.2f}'.format)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LANGUAGES = ['en', 'es']\n",
    "language_dict = dict(zip(LANGUAGES, ['English', 'Spanish']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return '{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "if not path.exists():\n",
    "    tar = tarfile.open('data.tar.gz', \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### TED 2013 English & Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "SOURCE = 'TED'\n",
    "FILE_NAME = 'TED2013'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Data source: http://opus.nlpl.eu/TED2013.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ted.com/talks/stephen_palumbi_following_the_mercury_trail.html\n",
      "There's a tight and surprising link between the ocean's health and ours, says marine biologist Stephen Palumbi. He shows how toxins at the bottom of the ocean food chain find their way into our bodies, with a shocking story of toxic contamination from a Japanese fish market. His work points a way forward for saving the oceans' health -- and humanity's.\n",
      "fish,health,mission blue,oceans,science\n",
      "899\n",
      "Stephen Palumbi: Following \n"
     ]
    }
   ],
   "source": [
    "filename = Path('data', 'TED', 'TED2013.en')\n",
    "print(filename.read_text()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tokenize & Clean Sentences\n",
    "\n",
    "Models expect data provided as a single sentence per line. We'll remove punctuation after using `spaCy`'s parser to tokenize the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def read_sentences(path, min_sent_length=3):\n",
    "    stats = pd.DataFrame()\n",
    "    sentences = []\n",
    "    skipped, word_count = 0, 0\n",
    "    \n",
    "    with open(path) as source:\n",
    "        for sentence in source:\n",
    "            # remove short sentences and urls (for TED data)\n",
    "            n_words = len(sentence.split())\n",
    "            if n_words < min_sent_length or sentence.startswith('http:///'):\n",
    "                skipped += 1\n",
    "            else:\n",
    "                word_count += n_words\n",
    "                sentences.append(sentence.strip())\n",
    "                \n",
    "    stats = pd.Series({'Sentences': len(sentences),\n",
    "                       '# Words': word_count,\n",
    "                       'Skipped': skipped})\n",
    "    return sentences, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "marked": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_sentences(sents, nlp, path, lang):\n",
    "    exclude = ['PUNCT', 'SYM', 'X']\n",
    "    start = time()\n",
    "    vocab = Counter()\n",
    "    sents = nlp.pipe(sents)\n",
    "    d = []\n",
    "    with open(path / 'ngrams_1.txt'.format(language), 'a') as f:\n",
    "        for i, sent in enumerate(sents):\n",
    "            if i % 20000 == 0 and i > 0:\n",
    "                print(i, end=' ')\n",
    "            d.extend([[i, w.text, w.pos_] for w in sent])\n",
    "            clean_sentence = [w.text.lower() for w in sent if w.pos_ not in exclude]\n",
    "            vocab.update(clean_sentence)\n",
    "            f.write(' '.join(clean_sentence) + '\\n')\n",
    "\n",
    "    vocab = pd.Series(vocab).sort_values(ascending=False).to_frame('count')\n",
    "    with pd.HDFStore(path.parent / 'vocab.h5') as store:\n",
    "        store.put('/'.join([lang, 'vocab']), vocab)\n",
    "        store.put('/'.join([lang, 'tokens']), pd.DataFrame(d, columns=['sent_id', 'token', 'pos']))\n",
    "    duration = time() - start\n",
    "    print('\\n\\tDuration: ', format_time(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 20000 40000 60000 80000 100000 120000 140000 \n",
      "\tDuration:  00:09:27\n",
      "es: 20000 40000 60000 80000 100000 120000 140000 \n",
      "\tDuration:  00:08:02\n"
     ]
    }
   ],
   "source": [
    "sentences, stats = {}, pd.DataFrame()\n",
    "\n",
    "for language in LANGUAGES:\n",
    "    source_path =  Path('data', SOURCE, '{}.{}'.format(FILE_NAME, language))\n",
    "    sentences[language], stats[language_dict[language]] = read_sentences(source_path)\n",
    "    \n",
    "    print(language, end=': ')\n",
    "    target_path = Path('vocab', SOURCE, language)\n",
    "    if not target_path.exists():\n",
    "        target_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    clean_sentences(sentences[language], spacy.load(language), target_path, language)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Corpus Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th># Words</th>\n",
       "      <td>2,640,928</td>\n",
       "      <td>2,548,942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentences</th>\n",
       "      <td>152,729</td>\n",
       "      <td>151,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skipped</th>\n",
       "      <td>5,166</td>\n",
       "      <td>6,045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             English    Spanish\n",
       "# Words    2,640,928  2,548,942\n",
       "Sentences    152,729    151,850\n",
       "Skipped        5,166      6,045"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.applymap(lambda x: '{:,d}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(Path('vocab', SOURCE, 'vocab.h5')) as store:\n",
    "    store.put('stats', stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspect Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"There's a tight and surprising link between the ocean's health and ours, says marine biologist Stephen Palumbi. He shows how toxins at the bottom of the ocean food chain find their way into our bodies, with a shocking story of toxic contamination from a Japanese fish market. His work points a way forward for saving the oceans' health -- and humanity's.\",\n",
       " 'Stephen Palumbi: Following the mercury trail',\n",
       " 'It can be a very complicated thing, the ocean.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['en'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Existe una estrecha y sorprendente relación entre nuestra salud y la salud del océano, dice el biologo marino Stephen Palumbi. Nos muestra, através de una impactante historia acerca de la contaminación tóxica en el mercado pesquero japonés, como las toxinas de la cadena alimenticia del fondo oceánico llegan a nuestro cuerpo.',\n",
       " 'Stephen Palumbi: Siguiendo el camino del mercurio.',\n",
       " 'El océano puede ser una cosa muy complicada.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences['es'][:3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_ngrams(language, max_length=3):\n",
    "    \"\"\"Using gensim to create ngrams\"\"\"\n",
    "    \n",
    "    path = Path('vocab', SOURCE, language)\n",
    "    n_grams = pd.DataFrame()\n",
    "    start = time()\n",
    "    for n in range(2, max_length + 1):\n",
    "        print(n, end=' ')\n",
    "        \n",
    "        sentences = LineSentence(str(path / 'ngrams_{}.txt'.format(n-1)))\n",
    "        phrases = Phrases(sentences, threshold=100, min_count=10)\n",
    "\n",
    "        s = pd.Series({k.decode('utf-8'): v for k,\n",
    "                       v in phrases.export_phrases(sentences)}) \n",
    "        s = s.to_frame('score').reset_index().rename(\n",
    "            columns={'index': 'phrase'}).assign(length=n)\n",
    "        \n",
    "        n_grams = pd.concat([n_grams, s])\n",
    "        grams = Phraser(phrases)\n",
    "        sentences = grams[sentences]\n",
    "        \n",
    "        with open(path / 'ngrams_{}.txt'.format(n), 'w') as f:\n",
    "            for sentence in sentences:\n",
    "                f.write(' '.join(sentence) + '\\n')\n",
    "                \n",
    "    n_grams = n_grams.sort_values('score', ascending=False)\n",
    "    n_grams.phrase = n_grams.phrase.str.replace('_', ' ')\n",
    "    n_grams['ngram'] = n_grams.phrase.str.replace(' ', '_')\n",
    "    \n",
    "    with pd.HDFStore(Path(path.parent / 'vocab.h5')) as store:\n",
    "        store.put('/'.join([language, 'ngrams']), n_grams)\n",
    "        \n",
    "    print('\\n\\tDuration: ', format_time(time() - start))\n",
    "    print('\\tngrams: {:,d}\\n'.format(len(n_grams)))\n",
    "    print(n_grams.groupby('length').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " en 2 3 \n",
      "\tDuration:  00:01:13\n",
      "\tngrams: 1,016\n",
      "\n",
      "length\n",
      "2    906\n",
      "3    110\n",
      "dtype: int64\n",
      "\n",
      " es 2 3 \n",
      "\tDuration:  00:00:41\n",
      "\tngrams: 508\n",
      "\n",
      "length\n",
      "2    462\n",
      "3     46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for language in LANGUAGES:\n",
    "    print('\\n', language, end=' ')\n",
    "    create_ngrams(language)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "465px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
